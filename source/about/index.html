<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About</title>
    <style type="text/css">
        div#resume {
            min-width: 310px;
            width: 100%;
            font: 16px Helvetica, Avernir, sans-serif;
            line-height: 24px;
            color: #000
        }

        div#resume img {
            float: right;
            padding: 10px;
            width: 100%;
            background: #fff;
            margin: 0 30px;
            transform: rotate(-4deg);
            box-shadow: 0 0 4px rgba(0, 0, 0, .3);
            width: 30%;
            max-width: 220px
        }

        .title h1 {
            text-align: center;
            font-size: larger;
        }

        h2 {
            padding-top: 20px;
        }

        .school .rank {
            color: red;
            font-size: large;
            font-weight: bold;
        }

        .github .github-chart {
            text-align: center;
        }

        .honors .nice {
            color: purple;
            font-size: larger;
            font-weight: bold;
        }

        .education {
            width: 100%;
        }

        .school {
            display: flex;
            flex-direction: column;
        }

        .school ul {
            list-style-type: none;
            margin: 0;
            padding: 0;
        }

        .school li {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }

        .school-info {
            flex-grow: 1;
            margin-left: 20px;
        }

        .school-logo {
            width: 12.5%;
        }

        .microsoft-logo {
            width: 20%;
        }

        .research-publication .title {
            color: purple;
            font-size: medium;
            font-weight: bolder;
        }

        .research-publication .title:hover {
            color: black; /* Sets the blog link color */
        }

        .research-publication .special {
            color: red;
            font-size: medium;
            font-weight: bold;
        }

        .research-publication li {
            list-style-type: none;
        }

        .details {
            font-style: italic; /* Italicizes the text */
            color: #6c757d; /* Sets a light gray color */
            margin-top: 5px; /* Adds some spacing above */
            display: block; /* Makes sure it takes a full line */
        }
        
        .blog-link {
            color: #2c6bcb; /* Sets the blog link color */
            text-decoration: none; /* Removes the underline from the link */
        }
        
        .blog-link:hover {
            text-decoration: underline; /* Adds underline on hover for the link */
        }

        .icon {
            width: 1.2em; /* Matches the typical size of Font Awesome icons */
            height: 1.2em; /* Ensures the image is square like the icons */
            margin-left: 2px; /* Adds some space to the left */
            vertical-align: -0.15em; /* Slightly adjusts the vertical alignment */
        }
        
        .fa {
            font-size: 1.2em; /* Ensures Font Awesome icons are the same size as the image */
            vertical-align: -0.15em; /* Slightly adjusts the vertical alignment */
        }

        .projects-section .special {
            color: red;
            font-size: medium;
            font-weight: bold;
        }

        .projects-section h3 {
            font-size: 16px;
            /* Default size for many browsers' paragraph text */
            font-weight: normal;
            /* Removes the bold styling of h3 */
            margin: 1em 0;
            /* Default margin for many browsers' paragraph text */
            line-height: 1.5;
            /* Line spacing similar to paragraphs */
            margin-top: 10px;
            /* Adjust this value as needed */
            margin-bottom: 5px;
            /* Adjust this value as needed */
        }
    </style>
</head>

<body>
    <div class="content">
        <div class="intro">
            <!-- <div id="resume">
                <img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/WechatIMG38.jpeg" alt="Wang Lei">
            </div> -->
            <h2>Introduction</h2>
            <p>
                He is currently a second year postgraduate student in University of Chinese Academy of Sciences <a
                    href="https://www.ucas.ac.cn/">UCAS</a>, Institute of
                Computing Technology <a href="http://www.ict.ac.cn/">ICT</a>, advised by Yinhe Han and Haobo Xu. He is also a full-time research intern in
                <a href="https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia">
                    System Research Group </a> of Microsoft Research Asia(MSRA), advised by <a
                    href="https://www.microsoft.com/en-us/research/people/jxue/">Dr. Jilong Xue</a>
                and <a href="https://xysmlx.github.io/">Dr. Lingxiao Ma</a>.
            </p>
            <p>
                And he is now focusing on :
            <ul>
                <li>
                    <a href="https://github.com/microsoft/SparTA/tree/nmsparse_artifact">Sparse Tensor Computation</a>
                </li>
                <li>
                    <a href="https://github.com/microsoft/nnfusion/tree/LadderLLM">on-device llm inference</a>
                </li>
                <li>
                    <a href="https://github.com/LeiWang1999/ZYNQ-NVDLA">Opensoure Accelerator System Design</a>
                </li>
                <li>
                    <a href="https://github.com/OAID/Tengine">CPU Fallback based on Tengine</a> [<a
                        href="https://github.com/LeiWang1999/ZYNQ-NVDLA/blob/master/TengineTalk.pdf">slides</a>] [<a
                        href="https://www.bilibili.com/video/BV1z44y1478k">recording</a>]
                </li>
            </ul>
            </p>
            <p>
                He also enjoys writing <a href="https://leiblog.wang">technical posts</a> and contributes to various
                open-source communities, including Microsoft NNFusion, Apache TVM, and Tengine etc.
            </p>
            <div class="detail">
                <img class="avatar" src="http://leiblog.wang/static/image/2020/11/long_avatar.jpg" alt="avatar">
            </div>
            <div class="github">
                <h3 class="github-title">LeiWang1999's Github Chart</h3>
                <div class="github-chart">
                    <img src="https://ghchart.rshah.org/LeiWang1999" alt="LeiWang1999's Github chart"
                        style=" height: 125px; box-shadow: none;">
                </div>
            </div>
        </div>

        <div class="education">
            <h2>Education</h2>
            <div class="school">
                <ul>
                    <li>
                        <div class="school-info">
                            <b>University of Chinese Academy of Science</b><br>
                            <b>Institute of Computing Technology</b><br>
                            Master in Computer Science(Aug. 2021 - Present)
                        </div>
                        <div class="school-logo">
                            <img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/ucasLogo.png" width="100%">
                        </div>
                    </li>
                    <li>
                        <div class="school-info">
                            <b>Nanjing Tech University</b><br>
                            Bachor in Electronic Engineering(Aug. 2017 - Jun. 2021) <br>
                            Overall GPA: <span class="rank">3.95/4.00</span> <br>
                            Ranking: 1/59
                        </div>
                        <div class="school-logo">
                            <img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/20230810200621.png"
                                width="100%">
                        </div>
                    </li>
                </ul>
            </div>
        </div>

        <div class="honors">
            <h2>Awards & Honors</h2>
            <div class="scholarship">
                <ul>
                    <li class="nice">2018 Chinese National Scholarship(Top 0.3%)</li>
                    <li>2021 Excellent New Student Award of Chinese Academy of Science</li>
                    <li class="nice">Njtech <b>Person of Year 2020</b></li>
                </ul>
            </div>
            <div class="awards">
                <ul>
                    <li class="nice">First Price of 2019 NUEDC (Top 0.5%)</a> (全国大学生电子设计竞赛)
                    </li>
                    <li>
                        First Price of 2018 Electronic Design Competition of Province</a>
                    </li>
                    <li>
                        Third Price of Integrated Circuit Innovation and Entrepreneurship Competition (<a
                            href="http://leiblog.wang/FPGA车牌识别/">FPGA hardware
                            Accelerator for digital recognition</a>)
                    </li>
                    <li>Third prize of National FPGA Competition (<a href="http://leiblog.wang/ZYNQ声源定位波束形成/">FPGA based
                            FOSDA Alogrithom Implementation</a>) </li>
                </ul>
            </div>
        </div>

        <div class="education">
            <h2>Experience</h2>
            <div class="school">
                <ul>
                    <li>
                        <div class="school-info">
                            <b><a href="https://www.youdao.com/">Netease Intelligent Hardware R&D Department</a></b>
                            <br>
                            <span>Bei Jing, China</span>
                            <br>
                            <span>NPU Development intern. (Sep. 2021 - Oct. 2021)</span>
                        </div>
                        <div class="school-logo">
                            <img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/600px-NetEase_logo.png"
                                width="100%">
                        </div>
                    </li>
                    <li>
                        <div class="school-info">
                            <b><a
                                    href="https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/">Microsoft
                                    Research Asia</a></b>
                            <br>
                            <span>Bei Jing, China</span>
                            <br>
                            <span>Systems Research intern. (April. 2022 - now)</span>
                        </div>
                        <div class="microsoft-logo">
                            <img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/20230810201214.png"
                                width="100%">
                        </div>
                    </li>
                </ul>
            </div>
        </div>

        <div class="research-publication">
            <h2>Publications</h2>
            <div>
                <div id="t-mac">
                    <a href="https://arxiv.org/html/2407.00088v1" class="title"><strong>T-MAC: CPU Renaissance via Table Lookup for Low-Bit LLM Deployment on Edge</strong></a>
                    <a href="https://github.com/microsoft/T-MAC"><i class="fa-brands fa-github" style="color: #B197FC;"></i></a>
                    <a href="https://github.com/microsoft/T-MAC"><i class="fa-regular fa-folder-open"></i></a>
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#available"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#functional"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#reproduced"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_reproduced_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <br>
                    <span class="authors">Jianyu Wei, Shijie Cao, Ting Cao, Lingxiao Ma, <b>Lei Wang</b>, Yanyong Zhang, Mao Yang</span><br>
                    <span class="details">
                        <em>Proceedings of the Nineteenth European Conference on Computer Systems.</em>, <em>EuroSys</em> 2025
                    </span>
                    <br>
                </div>

                <div id="ladder">
                    <a href="https://www.usenix.org/system/files/osdi24-wang-lei.pdf" class="title"><strong>Enabling Efficient Low-Precision Deep Learning Computing through Hardware-aware Tensor Transformation</strong></a>
                    <a href="https://github.com/microsoft/BitBLAS"><i class="fa-brands fa-github" style="color: #B197FC;"></i></a>
                    <a href="https://github.com/microsoft/BitBLAS/tree/osdi24_ladder_artifact"><i class="fa-regular fa-folder-open"></i></a>
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#available"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#functional"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#reproduced"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_reproduced_dl.jpg" alt="ACM artifact Logo" class="icon"></a>  
                    <br>
                    <span class="authors"><b>Lei Wang</b>, Lingxiao Ma, Shijie Cao, Quanlu Zhang, Jilong Xue, Yining Shi, Ningxin Zheng, Ziming Miao, Fan Yang, Ting Cao, Yuqing Yang, Mao Yang</span><br>
                    <span class="details">
                        <em>18th USENIX Symposium on Operating Systems Design and Implementation</em>, <em>OSDI</em>, 2024
                    </span>
                    <br>
                </div>
                
                <div id="1.58b">
                    <a href="https://arxiv.org/pdf/2402.17764.pdf" class="title"><strong>The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits</strong></a>
                    <br>
                    <span class="authors">Shuming Ma, Hongyu Wang, Lingxiao Ma, <b>Lei Wang</b>, Wenhui Wang, Shaohan Huang, Li Dong, Ruiping Wang, Jilong Xue, Furu Wei</span><br>
                    <span class="details">
                        <em>Arxiv</em>, 2024. <strong class="special"> HG Daily Paper TOP1!</strong>
                    </span>
                    <br>
                </div>
                
                <div id="primpar">
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3620666.3651357" class="title"><strong>PrimPar: Efficient Spatial-temporal Tensor Partition for Large Transformer Model Training</strong></a>
                    <br>
                    <span class="authors">Haoran Wang, <b>Lei Wang</b>, Haobo Xu, Ying Wang, Yinhe Han</span><br>
                    <span class="details">
                        <em>ACM International Conference on Architectural Support for Programming Languages and Operating Systems</em>, <em>ASPLOS</em>, 2024
                    </span>
                    <br>
                </div>  
                
                <div id="lut-tensorcore">
                    <a href="https://arxiv.org/abs/2408.06003" class="title"><strong>LUT TENSOR CORE: Lookup Table Enables Efficient Low-Bit LLM Inference Acceleration</strong></a>
                    <br>
                    <span class="authors">Zhiwen Mo, <b>Lei Wang</b>, Jianyu Wei, Zhichen Zeng, Shijie Cao, Lingxiao Ma, Naifeng Jing, Ting Cao, Jilong Xue, Fan Yang, Mao Yang</span><br>
                    <span class="details">
                        <em>Arxiv</em>, 2024
                    </span>
                    <br>
                </div>
                
                <div id="conv-stencil">
                    <a href="https://dl.acm.org/doi/10.1145/3627535.3638476" class="title"><strong>ConvStencil: Transform Stencil Computation to Matrix Multiplication on Tensor Cores</strong></a>
                    <br>
                    <span class="authors">Yuetao Chen, Kun Li, Yuhao Wang, Donglin Bai, <b>Lei Wang</b>, Lingxiao Ma, Liang Yuan, Yunquan Zhang, Ting Cao, Mao Yang</span><br>
                    <span class="details">
                        <em>Symposium on Principles and Practice of Parallel Programming</em>, <em>PPoPP</em>, 2024. <strong class="special"> Best Paper Award!</strong>
                    </span>
                    <br>
                </div>
                
                <div id="ladder-poster">
                    <a href="#" class="title"><strong>Efficient Tensor Compilation on Customized Data Format</strong></a>
                    <br>
                    <span class="authors"><b>Lei Wang</b>, Lingxiao Ma, Shijie Cao, Ningxin Zheng, Quanlu Zhang</span><br>
                    <span class="details">
                        <em>17th USENIX Symposium on Operating Systems Design and Implementation (Poster)</em>, <em>OSDI</em>, 2023
                    </span>
                    <br>
                </div>
                
                <div id="pimcomp">
                    <a href="https://arxiv.org/pdf/2307.01475.pdf" class="title"><strong>PIMCOMP: A Universal Compilation Framework for Crossbar-based PIM DNN Accelerators</strong></a>
                    <br>
                    <span class="authors">Sun Xiaotian, Wang Xinyu, Li Wanqian, <b>Wang Lei</b>, Han Yinhe, Chen Xiaoming</span><br>
                    <span class="details">
                        <em>60th Design Automation Conference</em>, <em>DAC</em>, 2023
                    </span>
                    <br>
                </div>
                
                <div id="pimsyn">
                    <a href="https://github.com/chenxm1986/PIM-Toolchain/tree/main/papers/pimsyn-nn.pdf" class="title"><strong>PIMSYN: Synthesizing Processing-in-memory CNN Accelerators</strong></a>
                    <br>
                    <span class="authors">Wanqian Li, Xiaotian Sun, Xinyu Wang, <b>Lei Wang</b>, Yinhe Han, Xiaoming Chen</span><br>
                    <span class="details">
                        <em>Design, Automation and Test in Europe Conference</em>, <em>DATE</em>, 2024
                    </span>
                    <br>
                </div>

                <div id="nmsparse">
                    <a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/05/N_M_Sparse_kernels__MLSys23.pdf" class="title"><strong>Efficient GPU Kernels for N:M-Sparse Weights in Deep Learning</strong></a>
                    <a href="https://github.com/microsoft/SparTA/tree/nmsparse"><i class="fa-brands fa-github" style="color: #B197FC;"></i></a>
                    <a href="https://github.com/microsoft/SparTA/tree/nmsparse_artifact"><i class="fa-regular fa-folder-open"></i></a>
                    <a href="https://mlsys.org/media/mlsys-2023/Slides/2466.pdf"><i class="fa-regular fa-file-powerpoint"></i></a>
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#available"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_available_dl.jpg" alt="ACM artifact Logo" class="icon"></a>
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#functional"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/artifacts_evaluated_functional_dl.jpg" alt="ACM artifact Logo" class="icon"></a>
                    <a href="https://www.acm.org/publications/policies/artifact-review-and-badging-current#reproduced"><img src="https://www.acm.org/binaries/content/gallery/acm/publications/replication-badges/results_reproduced_dl.jpg" alt="ACM artifact Logo" class="icon"></a>
                    <br>
                    <span class="authors">Lin Bin*, Zheng Ningxin*, <b>Wang Lei*</b>, Cao Shijie, Ma Lingxiao, Zhang Quanlu, Zhu Yi, Cao Ting, Xue Jilong, Yang Yuqing, et al. (* represents co-first author)</span><br>
                    <span class="details">
                        <em>Proceedings of Machine Learning and Systems</em>, <em>MLSYS</em>, 2023
                    </span>
                <br>
                </div>

            </div>
        </div>

        <div class="projects-section">
            <h2>Projects</h2>
            <ul>
                <li class="project-item">
                    <h3><a href="https://github.com/microsoft/BitBLAS"><strong>Microsoft BitBLAS</strong></a>, 2024<strong class="special"> Lead! </strong>
                    <a href="https://github.com/microsoft/BitBLAS"><i class="fa-brands fa-github" style="color: #B197FC;"></i></a>
                    </h3>
                    <p>
                        BitBLAS is a library to support mixed-precision BLAS operations on GPUs, for example, the <code>W<sub>wdtype</sub>A<sub>adtype</sub></code> mixed-precision matrix multiplication where <code>C<sub>cdtype</sub>[M, N] = A<sub>adtype</sub>[M, K] &times; W<sub>wdtype</sub>[N, K]</code>.
                        BitBLAS aims to support efficient mixed-precision DNN model deployment, especially the <code>W<sub>wdtype</sub>A<sub>adtype</sub></code> quantization in large language models (LLMs), for example:
                    </p>
                </li>
                <!-- Project 1 -->
                <li class="project-item">
                    <h3><strong>FPGA Accelerator for Digital Recognition, 2020</strong></h3>
                    <p>
                        Utilizing FPGA technology, this project aims to provide accelerated digital analysis during the
                        time
                        when convolutional neural networks began to gain prominence. This enhancement allowed for faster
                        and
                        more efficient digital recognition processes.
                        <br>
                        [<a href="https://leiblog.wang/FPGA%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/" class="project-link">
                            <i class="fa fa-video"></i> Watch the Video
                        </a>]
                    </p>
                </li>

                <!-- Project 2 -->
                <li class="project-item">
                    <h3><strong>FPGA Accelerator for Beam Forming, 2020</strong></h3>
                    <p>
                        With the aim of identifying sound location, this FPGA accelerator leverages a tetragonal
                        microphone
                        array to enhance sounds from specific points, we named the project FOSDA.
                        <br>
                        [<a href="https://leiblog.wang/ZYNQ%E5%A3%B0%E6%BA%90%E5%AE%9A%E4%BD%8D%E6%B3%A2%E6%9D%9F%E5%BD%A2%E6%88%90/"
                            class="project-link">
                            <i class="fa fa-video"></i> Watch the Video
                        </a>]
                    </p>
                </li>

                <!-- Project 3 -->
                <li class="project-item">
                    <h3><strong>Full Stack FPGA Implementation of NVDLA, 2021</strong></h3>
                    <p>
                        This project involved a full-stack FPGA implementation of the open-source Deep Learning
                        Accelerator
                        Framework, NVDLA. To enhance the utility of this accelerator, he designed a new compiler and
                        runtime framework. This allowed networks to do transition between CPU fallbacks and hardware
                        acceleration, ensuring optimal performance and usability.
                        <br>
                        [<a href="https://zhuanlan.zhihu.com/p/378202360" class="project-link">
                            <i class="fa fa-book"></i> Read the Post: DLA Deploy
                        </a>]
                        [<a href="https://zhuanlan.zhihu.com/p/401943271" class="project-link">
                            <i class="fa fa-book"></i> Read the Post: Compiler Design
                        </a>]
                        [<a href="https://github.com/LeiWang1999/ZYNQ-NVDLA" class="project-link">
                            <i class="fa fa-code"></i> View Github
                        </a>]
                    </p>
                </li>
                <li class="project-item">
                    <h3><strong>Opensource Contributions [<a href="https://github.com/LeiWang1999/">Github</a>]</strong>
                    </h3>
                    Familar with Microsoft NNFusion, Apache TVM, Tengine, etc.
                </li>
            </ul>
        </div>
        
        <div class="news"></div>
            <h2>[Invited] Talks</h2>
            <div id="talks-20241026" class="detail">
                <span>[10/26/24]</span>
                <a href="https://www.msra.cn/">[GPU MODE]</a>
                <span>BitBLAS/Ladder: Enabling Efficient Low-Precision 
                    Deep Learning Computing</span>
                <br>
                <a href="https://leiblog.wang/static/2024-09-16/GPUMODE_TALK_20241026.pdf">
                    <i class="fa-regular fa-file-powerpoint"></i>
                    <strong>[Slides]</strong>
                </a>
                <a href="https://www.youtube.com/watch?v=iA49QqWwMcA&t=257s">
                    <i class="fa fa-video"></i>
                    <strong>[Record]</strong>
                </a>
                <a href="https://github.com/microsoft/BitBLAS/tree/main/tutorials">
                    <i class="fa fa-book"></i>
                    <strong>[Tutorials]</strong>
                </a>
                <br>
            </div>
            <div id="talks-20240912" class="detail">
                <span>[09/12/24]</span>
                <a href="https://www.msra.cn/">[MSRA]</a>
                <span>BitBLAS/Ladder: Enabling Efficient Low-Precision 
                    Deep Learning Computing</span>
                <br>
                <a href="https://1drv.ms/b/c/4c1511b24254d525/EVGnfusejlZMlJ1ZazHhQNQBHPWyGN_PZznGzHjjUPexag?e=YR5cuB">
                    <i class="fa-regular fa-file-powerpoint"></i>
                    <strong>[Slides]</strong>
                </a>
                <a href="https://1drv.ms/v/c/4c1511b24254d525/EcfHiqAFctpAmBwWyrFuIaABxNa7rFG81QHuAaPbfzkhgQ?e=wXfaGm">
                    <i class="fa fa-video"></i>
                    <strong>[Record]</strong>
                </a>
                <br>
            </div>
            <div id="talks-20240912" class="detail">
                <span>[09/12/24]</span>
                <a href="https://www.noahlab.com.hk/#/home">[Huawei Noah Lab]</a>
                <span>BitBLAS: Enabling Efficient Low-Precision 
                    Deep Learning Computing</span>
                <br>
                <a href="https://leiblog.wang/static/2024-09-16/BitBLAS-Slides-20240911.pdf">
                    <i class="fa-regular fa-file-powerpoint"></i>
                    <strong>[Slides]</strong>
                </a>
                <br>
            </div>
            <div id="talks-20210923" class="detail">
                <span>[09/23/21]</span>
                <a href="https://github.com/OAID/Tengine">[Tengine Community]</a>
                <span>Tengine后端之OpenDLA概述</span>
                <br>
                <a href="https://leiblog.wang/static/2024-09-16/TengineTalk.pdf">
                    <i class="fa-regular fa-file-powerpoint"></i>
                    <strong>[Slides]</strong>
                </a>
                <a href="https://www.bilibili.com/video/BV1z44y1478k">
                    <i class="fa fa-video"></i>
                    <strong>[Record]</strong>
                </a>
                <br>
            </div>            
        </div>
                
        <div class="news">
            <h2>Selected Media Reports</h2>
            <div>
                <div id="report-20240822" class="detail">
                    <span>[08/22/24]</span>
                    <span>[WeChat Official Account]</span>
                    <span>[微软亚洲研究院]</span>
                    <a href="https://mp.weixin.qq.com/s/UkUViacg2m8DRNEzovNS6Q"><strong>微软亚洲研究院多项创新技术，弥合大模型低比特量化与终端部署间鸿沟</strong></a>
                    <br>
                </div>
                <div id="report-20240817" class="detail">
                    <span>[08/17/24]</span>
                    <span>[Zhihu]</span>
                    <span>[微软亚洲研究院]</span>
                    <a href="https://zhuanlan.zhihu.com/p/715086069"><strong>顶尖高校优秀学子齐聚微软亚洲研究院新星科技节，论道科研！</strong></a>
                    <br>
                </div>
                <div id="report-20240809" class="detail">
                    <span>[08/09/24]</span>
                    <span>[WeChat Official Account]</span>
                    <span>[量子位]</span>
                    <a href="https://mp.weixin.qq.com/s/StA1BWmyRwnuFJWJONwniw"><strong>手机跑大模型提速4-5倍！微软亚研院开源新技术，有CPU就行</strong></a>
                    <br>
                </div>
                <div id="report-20240229" class="detail">
                    <span>[02/29/24]</span>
                    <span>[WeChat Official Account]</span>
                    <span>[机器之心]</span>
                    <a href="https://mp.weixin.qq.com/s/4qtD_S_cC8OF0GENBPP-_Q"><strong>BitNet b1.58：开启1-bit大语言模型时代</strong></a>
                    <br>
                </div>
            </div>
        </div>
    </div>
</body>

</html>
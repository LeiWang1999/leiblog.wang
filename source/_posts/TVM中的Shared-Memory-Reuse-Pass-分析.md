---
title: TVMä¸­çš„Shared Memory Reuse Pass åˆ†æ
categories:
  - Technical
tags:
  - TVM
  - MLSys
date: 2024-09-14 15:13:08
---

è¿‘æœŸåœ¨åŸºäºTVM(å…¶å®æ˜¯bitblas.tl) å¤ç°PPoPP 2023çš„ä¸€ç¯‡è®ºæ–‡[Stream-K: Work-centric Parallel Decomposition for Dense Matrix-Matrix Multiplication on the GPU](http://arxiv.org/abs/2301.03598) . ç®€å•æ¥è¯´ï¼Œè¿™ä¸ªæ–¹æ³•å¯ä»¥æŠŠkè½´å‡åŒ€åœ°åˆ‡åˆ†åˆ°æ¯ä¸ªSMä¸Šï¼Œä»è€Œç¼“è§£å°shapeä¸‹çš„SM Wavesæµªè´¹ï¼ˆBitBLASåœ¨Contiguous Batchingç­‰åœºæ™¯ä¸Šç¡®å®ç¢°åˆ°äº†è¿™æ ·çš„é—®é¢˜ï¼Œä¸ºäº†ä¼˜åŒ–è¿™éƒ¨åˆ†æ€§èƒ½ä¸å¾—å·²å»å¤ç°è¿™ä¸ªè®ºæ–‡çš„æ–¹æ³•ã€‚ç„¶è€Œè¿™ç¯‡Blogä¸è®²Stream-Kçš„ç®—æ³•ä¸å®ç°ç»†èŠ‚ï¼Œä¹Ÿä¸è®²BitBLAS, è€Œæ˜¯æ¥åˆ†æä¸€ä¸‹TVMçš„MergeSharedMemoryAllocationsè¿™ä¸€ä¸ªPassï¼ŒåŸå› æ˜¯é«˜æ•ˆçš„Stream-Kå®ç°éœ€è¦å¼•å…¥å¤§é‡çš„shared memoryï¼Œè€ŒTVMä¸­è´Ÿè´£è¿›è¡ŒLivenessåˆ†ææ¥åˆå¹¶shared memoryè®¿å­˜çš„è¿™ä¸ªPassï¼Œåœ¨å¤æ‚åœºæ™¯ä¸‹å­˜åœ¨BUGï¼Œå¯¼è‡´shared memoryçš„å¤ç”¨è¾¾ä¸åˆ°é¢„æœŸï¼Œé˜»æ­¢äº†æˆ‘ä»¬æ¢ç´¢æ›´å¤§çš„tile size. ä¸ºæ­¤ä¸å¾—ä¸å¯¹è¿™ä¸ªPassè¿›è¡Œä¸€ä¸‹æ”¹è¿›ï¼Œæœ¬æ–‡è®°å½•ä¸€ä¸‹å¯¹è¿™ä¸ªPassçš„åˆ†æå’Œä¿®æ”¹ï¼Œä»¥åŠæˆ‘ç›¸ä¿¡å¤§éƒ¨åˆ†TVMçš„ç”¨æˆ·åœ¨Hack TVMçš„ä»£ç çš„æ—¶å€™éƒ½ä¼šå¤´ç§ƒï¼Œç©¿æ’ä¸€äº›TVMçš„è®¾è®¡å’Œè°ƒè¯•ç»éªŒï¼‰


<div align="center" ><img src="https://github.com/LeiWang1999/Stream-k.tvm/raw/master/figures/image.png" alt="example" style="zoom:33%;" /></div>

<!-- more -->

### ä¸ºä»€ä¹ˆéœ€è¦ `MergeSharedMemoryAllocations` è¿™ä¸ª Pass

åœ¨é«˜æ€§èƒ½çš„GPU Kernelä¸­ï¼Œ**å…±äº«å†…å­˜ï¼ˆshared memoryï¼‰** çš„ä½¿ç”¨å¯¹äºæ€§èƒ½ä¼˜åŒ–è‡³å…³é‡è¦ï¼Œæ™®é€šçš„Tileåˆ’åˆ†éœ€è¦åœ¨Shared Memoryä¸ŠåšCacheï¼Œè½¯ä»¶æµæ°´è¿˜ä¼šæˆå€å¾—å¢åŠ Shared Memoryçš„ä½¿ç”¨ï¼ŒBlockå†…è·¨çº¿ç¨‹Reduceç­‰æ“ä½œä¹Ÿéœ€è¦é€šè¿‡Shared Memoryä½œä¸ºåª’ä»‹ã€‚ä»¥CUTLASSä¸ºä¾‹ï¼Œä¸éš¾å‘ç°é«˜æ€§èƒ½çš„Kerneléƒ½æœ‰ç€ä¸ä½çš„Stage(åŠè½¯ä»¶æµæ°´çš„å±‚æ•°ï¼Œä¸€èˆ¬ä¸º3ï¼Œæˆ–è€…4)ï¼Œè¿™åŒæ ·ä»£è¡¨ç€é«˜æ€§èƒ½çš„Kerneléœ€è¦ä½¿ç”¨ä¸å°çš„Shared Memoryç©ºé—´ã€‚è¯•æƒ³ä¸€ä¸‹ï¼Œç”¨æˆ·ä»¿ç…§CUTLASSçš„Tile Sizeæ‰‹å†™ä¸€ä¸ªé«˜æ€§èƒ½çš„Kernelï¼Œä½†æ˜¯å› ä¸ºæ²¡æœ‰åšShared Memoryçš„Reuseï¼Œå¯¼è‡´ä½¿ç”¨çš„Shared Memoryæ¯”CUTLASSå¤šå‡ºä¸€åŠï¼Œå¾€å¾€å°±ä¼šå¯¼è‡´ç¼–è¯‘å¤±è´¥ï¼Œä¸§å¤±äº†ä¸€äº›ä¼˜åŒ–æœºä¼šã€‚

è€Œæ˜¾ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€äº›é™æ€åˆ†æçš„æ–¹æ³•ï¼Œä¾‹å¦‚Liveness Analysisï¼Œæ¥åˆ†æå‡ºæ¯ä¸ªBufferçš„ç”Ÿå‘½å‘¨æœŸï¼Œä»è€Œæ±‚è§£å‡ºä¸€ä¸ªShared Memory Reuseçš„æ–¹æ¡ˆï¼Œè€Œåœ¨TVMä¸­ï¼Œå®ç°è¿™ä¸€æ–¹æ¡ˆçš„Passå°±æ˜¯**MergeSharedMemoryAllocations**, å…¶ä¸»è¦åŠŸèƒ½æ˜¯åˆå¹¶å¤šæ¬¡ä½¿ç”¨ä½†ç”Ÿå‘½å‘¨æœŸä¸é‡å çš„å…±äº«å†…å­˜å—ã€‚é€šè¿‡è¿™æ ·çš„åˆå¹¶æ“ä½œï¼ŒMLC(Machine Learning Compiler)å¯ä»¥å‡å°å­˜å‚¨å™¨çš„ç¢ç‰‡åŒ–ï¼Œæå‡è®¡ç®—çš„æ€§èƒ½å’Œèµ„æºåˆ©ç”¨ç‡ã€‚

è€ƒè™‘ä¸€ä¸ªç®€å•çš„çŸ©é˜µä¹˜æ³•ï¼ˆMatrix-Matrix Multiplication, GEMMï¼‰åœºæ™¯ï¼Œåœ¨è¿™ç§åœºæ™¯ä¸‹æˆ‘ä»¬éœ€è¦æŠŠè¾“å…¥çŸ©é˜µå’Œéƒ¨åˆ†ç»“æœä¸´æ—¶å­˜å‚¨åœ¨å…±äº«å†…å­˜ä¸­ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚å‡è®¾æˆ‘ä»¬è¦è®¡ç®—çŸ©é˜µ `C = A * B`ï¼Œå…¶ä¸­çŸ©é˜µ `A` çš„ç»´åº¦ä¸º `MxK`ï¼ŒçŸ©é˜µ `B` çš„ç»´åº¦ä¸º `KxN`ã€‚

åœ¨ä¼ ç»Ÿçš„Tileåˆ†å—çŸ©é˜µä¹˜æ³•ï¼ˆBlock Matrix Multiplicationï¼‰ç®—æ³•ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†çŸ©é˜µ `A` å’Œ `B` åˆ‡åˆ†æˆå¤šä¸ªå°å—ï¼ˆTileï¼‰ï¼Œå¹¶å°†è¿™äº›å—åŠ è½½åˆ°å…±äº«å†…å­˜ä¸­è¿›è¡Œè®¡ç®—ã€‚è¿™æ ·åšçš„å¥½å¤„æ˜¯å¯ä»¥å……åˆ†åˆ©ç”¨å…±äº«å†…å­˜çš„é«˜å¸¦å®½å’Œä½å»¶è¿Ÿï¼Œå‡å°‘å¯¹å…¨å±€å†…å­˜çš„è®¿é—®æ¬¡æ•°ï¼Œä¾‹å¦‚ï¼Œåœ¨å¦‚ä¸‹çš„ä»£ç ç‰‡æ®µä¸­ï¼š

```cpp
// Allocate shared memory for matrix tiles
__shared__ float Asub[32][32];
__shared__ float Bsub[32][32];
__shared__ float Csub[32][32];

// Load sub-matrix into shared memory
Asub[threadIdx.y][threadIdx.x] = A[row + threadIdx.y][k + threadIdx.x];
Bsub[threadIdx.y][threadIdx.x] = B[k + threadIdx.y][col + threadIdx.x];

// Perform computation
for (int t = 0; t < 32; ++t) {
    Cvalue += Asub[threadIdx.y][t] * Bsub[t][threadIdx.x];
}

// Store into Csub
Csub[threadIdx.y][threadIdx.x] = Cvalue;

// Store into C
C[row + threadIdx.y][col + threadIdx.x] = Csub[threadIdx.y][threadIdx.x];
```

è¿™é‡Œçš„ `Asub` ,`Bsub` å’Œ`Csub`æ˜¯ä¸‰ä¸ªå¤§å°ä¸º `32x32` çš„å…±äº«å†…å­˜å—ï¼Œä¸€å…±ä¼šä½¿ç”¨3072ä¸ªfloatå¤§å°çš„shared memoryï¼Œä¸éš¾å‘ç°ï¼Œå½“ç¨‹åºæ‰§è¡Œåˆ°`Csub[threadIdx.y][threadIdx.x] = Cvalue;`çš„æ—¶å€™ï¼ŒAsubå’ŒBsubå…¶å®å·²ç»ä¸ä¼šè¢«ä½¿ç”¨åˆ°äº†ï¼Œæ­¤æ—¶æˆ‘ä»¬åº”è¯¥å¤ç”¨è¿™éƒ¨åˆ†å­˜å‚¨ï¼Œå€˜è‹¥å¦‚æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥çœä¸‹1024ä¸ªfloatå¤§å°çš„shared memroyï¼Œç›¸åº”çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ¢ç´¢æ›´å¤§çš„Tile Sizeæˆ–è€…Pipelineã€‚è€Œåœ¨å¸¸ç”¨çš„Tile Shapeä¸­ï¼Œå¾€å¾€æ˜¯BM~=BN >> BKçš„ï¼Œè¿™å°±å¯¼è‡´C_sharedå¾€å¾€å¾ˆå¤§ï¼Œä¸å¤ç”¨å­˜å‚¨ä¼šä¸ºç¡¬ä»¶å¸¦æ¥éå¸¸å¤§çš„å‹åŠ›ã€‚

### MergeSharedMemoryAllocations çš„åˆ†æå’Œæ”¹è¿›

é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç®€è¦å›é¡¾ä¸€ä¸‹è¿™ä¸ªPassçš„ä¿®æ”¹å†å²ï¼Œç¤¾åŒºçš„å¤§ä½¬**[masahi](https://github.com/masahi)**åœ¨2021å¹´çš„æ—¶å€™å†™äº†æœ€åŸå§‹çš„Passï¼Œ[\[CUDA\] Support multiple TIR-level dynamic shared memory allocations by masahi Â· Pull Request #8571 Â· apache/tvm (github.com)](https://github.com/apache/tvm/pull/8571) ï¼Œå½“æ—¶è¿˜æ²¡æœ‰æ´»è·ƒå˜é‡åˆ†æçš„å†…å®¹ï¼ŒçŒœæƒ³åªæ˜¯å› ä¸ºdynamic shared memoryåªèƒ½å£°æ˜ä¸€æ¬¡ï¼Œæ‰€ä»¥å¿…é¡»è¦æŠŠåŸæœ¬çš„å¤šä¸ªallocç»™æ•´åˆæˆä¸€ä¸ªï¼Œå¹´åº•çš„æ—¶å€™**[jinhongyii](https://github.com/jinhongyii)** åœ¨è¿™ä¸ªPassä¸Šå¢åŠ äº†å¯¹å„ä¸ªBufferçš„æ´»è·ƒå˜é‡åˆ†æï¼Œä½¿å¾—Bufferå¯ä»¥è¢«å¤ç”¨ï¼Œå†è¿™ä¹‹åçš„ä¸€äº›æ›´æ”¹å¤§éƒ¨åˆ†æ˜¯æ‰“æ‰“è¡¥ä¸ï¼ˆä¾‹å¦‚é’ˆå¯¹ä¸€äº›TVMçš„buildin intrinï¼Œä¾‹å¦‚å¼‚æ­¥æ‹·è´å’ŒTensorCoreç›¸å…³çš„æŒ‡ä»¤)ï¼Œå»å¹´çš„æ—¶å€™ï¼Œæˆ‘å¯¹è¿™ä¸ªPassåšäº†ä¸€ä¸ªç®€å•çš„æ”¹è¿›ï¼Œæé«˜äº†ä¸€äº›åœºæ™¯ä¸‹çš„å¤ç”¨ç‡ï¼Œå¹¶ä¸”å°†è¿™ä¸ªå†…å®¹æ‰©å±•åˆ°é™æ€Shared Memoryä¸­å»[\[CUDA\] Simple extend to optimize reuse for static shared memory. by LeiWang1999 Â· Pull Request #16342 Â· apache/tvm (github.com)](https://github.com/apache/tvm/pull/16342)ï¼Œä¸æ­¤åŒæ—¶ï¼Œè¿™ä¸ªPassçš„åå­—ä¹Ÿä»`MergeDynamicSharedMemoryAllocations`å˜æˆäº†`MergeSharedMemoryAllocations `.ï¼ˆè‡³äºä¸ºä»€ä¹ˆä¸all in dynamic shared memoryå‘¢ï¼Ÿå…¶å®ä½œè€…å½“æ—¶æ˜¯è¢«ThreadSyncè¿™ä¸ªPassç»™å‘äº†ï¼Œåœ¨dynamicçš„æ—¶å€™è«åå…¶å¦™å¤šæ’äº†å¾ˆå¤šsyncï¼Œå¯¼è‡´ç¬”è€…è®¤ä¸ºstaticåœ¨æŸäº›caseä¸‹è¦æ›´å¿«ï¼Œå¦‚ä»Šçœ‹æ¥ï¼Œè¿™ä¸¤è€…åˆ«æ— äºŒè‡´ï¼‰ã€‚

è®²è¿‡å†å²ï¼Œæˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹è¿™ä¸ªPassçš„æ‰§è¡Œè¿‡ç¨‹ï¼Œä»£ç çš„ä¸»ä½“åœ¨[merge_shared_memory_allocations.cc â€” LeiWang1999/tvm â€” GitHub](https://github.com/LeiWang1999/tvm/blob/bitblas/src/tir/transforms/merge_shared_memory_allocations.cc). å¦‚å›¾æ‰€ç¤ºï¼Œæœ€ä¸»è¦çš„Classæ˜¯SharedMemoryRewriterï¼Œä¸»è¦çš„æµç¨‹æ°›å›´ä¸‰éƒ¨ï¼Œç¬¬ä¸€æ­¥æ˜¯ä½¿ç”¨Visitor `SharedMemLinearAccessPatternFinder`æ¥è·å¾—ä¸€ä¸ªBufferçš„LinearAccessPatternï¼Œä»–ä¼šè¿”å›ä¸€ä¸ªä½œç”¨åŸŸæ¡ç›®ï¼Œè¿™ä¸ªæ¡ç›®æœ‰åŠ©äºæˆ‘ä»¬ç›´æ¥è¿›è¡ŒLivnessåˆ†æï¼ˆç”Ÿæˆæ¯ä¸ªbufferçš„genå’Œkill pointï¼‰ï¼Œæœ€åPassä¼šæ ¹æ®Livenessåˆ†æçš„ç»“æœç®—å‡ºå†…å­˜æ± çš„å¤§å°ï¼Œå’Œæ¯ä¸ªbufferçš„åç½®ï¼Œå¹¶æ”¹å†™è¯­æ³•æ ‘ä¸­å¯¹åº”Bufferçš„è®¿é—®èŠ‚ç‚¹ã€‚

<div align='center'><img src="https://leiblog-imgbed.oss-cn-beijing.aliyuncs.com/img/image-20240914230856853.png" alt="image-20240914230856853" style="zoom:50%;" /></div>

{% colorquote success %}
TVM Tips: StmtExprVisitorè¿™ä¸ªç±»å¯ä»¥è¢«ç”¨æ¥éå†TVM IRçš„è¯­æ³•æ ‘ï¼Œä¸€èˆ¬ç”¨æ¥ä»ASTä¸Šç»Ÿè®¡ä¸€äº›ä¿¡æ¯ï¼Œä¾‹å¦‚æ­¤å¤„çš„ä½œLinearAcessPatternï¼Œè€ŒStmtExprMutatoråˆ™è¢«ç”¨æ¥ä¿®æ”¹ASTä¸Šçš„èŠ‚ç‚¹ã€‚
{% endcolorquote %}

å…ˆåˆ†æ`SharedMemLinearAccessPatternFinder`è¿™ä¸ªVisitorï¼Œè¯¥ç±»æœ‰ä¸¤ä¸ªå…³é”®çš„æ•°æ®ç»“æ„ï¼š

```cpp
  /*! \brief record the touch list of statement. */
  struct StmtEntry {
    // The statement
    const Object* stmt;
    // The index in the linear_seq_ to point to end of the nested scope.
    // This is only set to non-zero if stmt is a nested scope.
    // if offset > 0, means this is the begin, the end entry is current_index + offset
    // if offset < 0, means this is the end, the begin entry is current_index + offset
    int64_t scope_pair_offset{0};
    // The buffer variables this statement touched.
    std::vector<const VarNode*> touched;
  };
  // The scope of each allocation
  struct AllocEntry {
    // the level in the scope stack
    size_t level{0};
    // allocation stmt
    const AllocateNode* alloc{nullptr};
  };
```

åœ¨TVMä¸­ï¼Œï¼Œåå­—åœ¨`Entry`çš„æ•°æ®ç»“æ„æ˜¯éå¸¸å¸¸è§çš„ï¼Œåœ¨æ•°æ®ç»“æ„è®¾è®¡ä¸­ï¼Œ`Entry`é€šå¸¸ç”¨æ¥è¡¨ç¤ºä¸€ä¸ªç‰¹å®šçš„æ•°æ®æ¡ç›®æˆ–è®°å½•ï¼Œåœ¨æ­¤å¤„ï¼Œå®ƒç”¨äºè®°å½•å’Œç®¡ç†å…±äº«å†…å­˜çš„åˆ†é…å’Œä½¿ç”¨ä¿¡æ¯ï¼Œä»¥æ”¯æŒåç»­çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚é€šè¿‡è¿™äº›æ¡ç›®ï¼Œåç»­çš„Passèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç¨‹åºçš„å†…å­˜ä½¿ç”¨æ¨¡å¼ï¼Œä»è€Œè¿›è¡Œç”Ÿå‘½å‘¨æœŸåˆ†æã€‚

`SharedMemLinearAccessPatternFinder`é¦–å…ˆç”Ÿæˆå‡º`AllocEntry`,è®°å½•çš„æ˜¯bufferçš„allocèŠ‚ç‚¹å¤„äºå†…å­˜çš„ç¬¬å‡ ä¸ªlevelï¼Œå…¶ä½™çš„ä¸»è¦åŠŸèƒ½æ˜¯è®°å½•æ¯ä¸ªä½œç”¨åŸŸçš„å¼€å§‹å’Œç»“æŸï¼Œå½¢æˆä¸€å¯¹ä½œç”¨åŸŸæ¡ç›®ï¼ˆscope entryï¼‰ï¼š
- å½“è¿›å…¥ä¸€ä¸ªæ–°ä½œç”¨åŸŸï¼ˆå¦‚ For å¾ªç¯æˆ– IfThenElse æ¡ä»¶åˆ†æ”¯ï¼‰æ—¶ï¼Œå®ƒä¼šå°†ä¸€ä¸ª `StmtEntry` æ¡ç›®æ¨å…¥ `linear_seq_`ï¼Œè¡¨ç¤ºè¯¥ä½œç”¨åŸŸçš„å¼€å§‹ï¼Œå¹¶åœ¨ä½œç”¨åŸŸç»“æŸæ—¶å†æ’å…¥ä¸€ä¸ªæ¡ç›®è¡¨ç¤ºç»“æŸã€‚
- è¿™ç§ç»“æ„è®°å½•äº†æ¯ä¸ªå…±äº«å†…å­˜åˆ†é…è¯­å¥å’Œä½¿ç”¨è¯­å¥çš„åµŒå¥—å…³ç³»ï¼Œä½¿åç»­çš„å­˜æ´»æ€§åˆ†æèƒ½å¤Ÿå‡†ç¡®åœ°æ‰¾å‡ºæ¯ä¸ªå†…å­˜å—çš„ç”Ÿå­˜å‘¨æœŸ

é‚£ä¹ˆï¼Œlevelä»£è¡¨çš„æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿå‡è®¾æœ‰ä»¥ä¸‹ä»£ç ç‰‡æ®µï¼ŒåŒ…å«äº†å¤šå±‚åµŒå¥—çš„ä½œç”¨åŸŸï¼š

```bash
Allocate(A, shared) // Level 0
for (int i = 0; i < N; ++i) {  // Level 1
    Allocate(B, shared)  // Level 1
    if (A[i] > 0) {  // Level 2
        Allocate(C, shared)  // Level 2
    } else {
        Allocate(D, shared)  // Level 2
    }
    // End of Level 2 scope
}
// End of Level 1 scope
```

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½œç”¨åŸŸå±‚æ¬¡å¦‚ä¸‹ï¼š

â€¢	Allocate(A, shared)ï¼šä½äºæœ€å¤–å±‚ï¼Œlevel ä¸º 0ã€‚
â€¢	Allocate(B, shared)ï¼šä½äº for å¾ªç¯å†…éƒ¨ï¼Œlevel ä¸º 1ã€‚
â€¢	Allocate(C, shared) å’Œ Allocate(D, shared)ï¼šä½äº if-else åˆ†æ”¯å†…éƒ¨ï¼Œlevel ä¸º 2ã€‚

åœ¨TVMçš„è¯­æ³•æ ‘è®¾è®¡ä¸­ï¼Œæœ€å¤–å±‚ä¸€èˆ¬æ˜¯AttrStmtï¼Œç”¨æ¥è®°å½•thread bindingç­‰ä¿¡æ¯ï¼Œè€ŒShared Memoryåªèƒ½åœ¨CUDA Kernelçš„æœ€å¤–å±‚æ¥Allocï¼Œæ‰€ä»¥AllocEntryçš„Levelä¸€èˆ¬éƒ½æ˜¯åœ¨Level 1.

ä»¥ä¸€ä¸ªè°ƒåº¦å®Œçš„çŸ©é˜µä¹˜æ³•ï¼ˆæ­¤å¤„ä»¥æˆ‘å®é™…ä½¿ç”¨çš„Stream-Kä¸ºä¾‹å­ï¼‰è¿›å…¥è¯¥Passä¹‹å‰(å·²ç»ç»è¿‡äº†SplitHostDevice, StorageRewriteç­‰å„ç§Pass)ä¸ºä¾‹å­:
```python
C = T.handle("float16", "global")
with T.decl_buffer((262144,), "float16", data=C) as C_1:
    C_shared = T.handle("float16", "shared.dyn")
    C_shared_1 = T.decl_buffer((1024,), "float16", data=C_shared, scope="shared.dyn")
    red_buf0 = T.handle("float16", "shared.dyn")
    red_buf0_1 = T.decl_buffer((65536,), "float16", data=red_buf0, scope="shared.dyn")
    B_dequantize_local = T.handle("float16", "local")
    B_dequantize_local_1 = T.decl_buffer((8,), "float16", data=B_dequantize_local, scope="local")
    B_shared_full_tiles = T.handle("int8", "shared.dyn")
    B_shared_full_tiles_1 = T.decl_buffer((32768,), "int8", data=B_shared_full_tiles, scope="shared.dyn")
    B_local = T.handle("int8", "local")
    B_local_1 = T.decl_buffer((4,), "int8", data=B_local, scope="local")
    A_shared_full_tiles = T.handle("float16", "shared.dyn")
    A_shared_full_tiles_1 = T.decl_buffer((16640,), "float16", data=A_shared_full_tiles, scope="shared.dyn")
    C_local = T.handle("float16", "local")
    C_local_1 = T.decl_buffer((8,), "float16", data=C_local, scope="local")
    pid = T.launch_thread("blockIdx.x", 108)
    C_local = T.allocate([8], "float16", "local")
    A_shared_full_tiles = T.allocate([16640], "float16", "shared.dyn")
    B_shared_full_tiles = T.allocate([32768], "int8", "shared.dyn")
    A_local = T.allocate([8], "float16", "local")
    B_local = T.allocate([4], "int8", "local")
    B_dequantize_local = T.allocate([8], "float16", "local")
    red_buf0 = T.allocate([65536], "float16", "shared.dyn")
    T.attr(red_buf0, "volatile_scope", 1)
    C_shared = T.allocate([1024], "float16", "shared.dyn")
    v = T.launch_thread("threadIdx.x", 128)
    v_1 = T.launch_thread("threadIdx.y", 1)
    v_2 = T.launch_thread("threadIdx.z", 1)
    T.attr(0, "pragma_import_c", metadata["tir.StringImm"][0])
    thread_bindings = T.launch_thread("threadIdx.x", 128)
    rk = T.launch_thread("threadIdx.y", 4)
    C_local_1[0:8] = T.Broadcast(T.float16(0), 8)
    A = T.handle("float16", "global")
    for i in T.unroll(2):
        T.ptx_cp_async("float16", A_shared_full_tiles, i * 4160 + v // 16 * 520 + rk * 128 + v % 16 * 8, A, i * 131072 + v // 16 * 16384 + rk * 128 + v % 16 * 8, 16)
    B = T.handle("int8", "global")
    with T.attr(0, "async_commit_queue_scope", 0):
        for i in range(2):
            T.ptx_cp_async("int8", B_shared_full_tiles, i * 8192 + rk * 2048 + thread_bindings * 16, B, pid * 524288 + i * 262144 + rk // 2 * 131072 + rk % 2 * 2048 + thread_bindings * 16 + 77594624, 16)
    for ko in range(31):
        T.tvm_storage_sync("shared.dyn")
        for i in T.unroll(2):
            T.ptx_cp_async("float16", A_shared_full_tiles, (ko + 1) % 2 * 8320 + i * 4160 + v // 16 * 520 + rk * 128 + v % 16 * 8, A, i * 131072 + v // 16 * 16384 + ko * 512 + rk * 128 + v % 16 * 8 + 512, 16)
        with T.attr(0, "async_commit_queue_scope", 0):
            for i in range(2):
                T.ptx_cp_async("int8", B_shared_full_tiles, (ko + 1) % 2 * 16384 + i * 8192 + rk * 2048 + thread_bindings * 16, B, pid * 524288 + i * 262144 + rk // 2 * 131072 + ko * 4096 + rk % 2 * 2048 + thread_bindings * 16 + 77598720, 16)
        T.attr(0, "async_wait_queue_scope", 0)
        T.attr(0, "async_wait_inflight_count", 1)
        T.tvm_storage_sync("shared")
        for ki in range(8):
            T.ptx_ldmatrix("float16", T.bool(False), 4, ".b16", A_local, 0, T.address_of(A_shared_full_tiles_1[ko % 2 * 8320 + rk * 128 + ki * 16]), thread_bindings % 16 * 520 + thread_bindings % 32 // 16 * 8)
            B_local_1[0:4] = B_shared_full_tiles_1[ko % 2 * 16384 + thread_bindings // 32 * 4096 + rk * 1024 + ki * 128 + thread_bindings % 32 * 4:ko % 2 * 16384 + thread_bindings // 32 * 4096 + rk * 1024 + ki * 128 + thread_bindings % 32 * 4 + 4]
            T.call_extern("handle", "decode_i4u_to_f16", T.address_of(B_local_1[0]), T.address_of(B_dequantize_local_1[0]), 8)
            T.ptx_mma("float16", "m16n8k16", "row", "col", "fp16", "fp16", "fp16", A_local, 0, B_dequantize_local, 0, C_local, 0, T.bool(False))
            T.ptx_mma("float16", "m16n8k16", "row", "col", "fp16", "fp16", "fp16", A_local, 0, B_dequantize_local, 4, C_local, 4, T.bool(False))
    with T.attr(0, "async_wait_queue_scope", 0):
        T.attr(0, "async_wait_inflight_count", 0)
        T.tvm_storage_sync("shared")
        for ki in range(8):
            T.ptx_ldmatrix("float16", T.bool(False), 4, ".b16", A_local, 0, T.address_of(A_shared_full_tiles_1[rk * 128 + ki * 16 + 8320]), thread_bindings % 16 * 520 + thread_bindings % 32 // 16 * 8)
            B_local_1[0:4] = B_shared_full_tiles_1[thread_bindings // 32 * 4096 + rk * 1024 + ki * 128 + thread_bindings % 32 * 4 + 16384:thread_bindings // 32 * 4096 + rk * 1024 + ki * 128 + thread_bindings % 32 * 4 + 16384 + 4]
            T.call_extern("handle", "decode_i4u_to_f16", T.address_of(B_local_1[0]), T.address_of(B_dequantize_local_1[0]), 8)
            T.ptx_mma("float16", "m16n8k16", "row", "col", "fp16", "fp16", "fp16", A_local, 0, B_dequantize_local, 0, C_local, 0, T.bool(False))
            T.ptx_mma("float16", "m16n8k16", "row", "col", "fp16", "fp16", "fp16", A_local, 0, B_dequantize_local, 4, C_local, 4, T.bool(False))
    for n in range(8):
        T.attr(T.comm_reducer(lambda x, y: x + y, [T.float16(0)]), "reduce_scope", T.reinterpret("handle", T.uint64(0)))
        T.tvm_storage_sync("shared.dyn")
        red_buf0_1[thread_bindings * 512 + v * 4 + rk] = C_local_1[n]
        T.tvm_storage_sync("shared.dyn")
        if rk < 2:
            red_buf0_1[thread_bindings * 512 + v * 4 + rk] = red_buf0_1[thread_bindings * 512 + v * 4 + rk] + red_buf0_1[thread_bindings * 512 + v * 4 + rk + 2]
        T.tvm_storage_sync("shared.dyn")
        if rk < 1:
            red_buf0_1[thread_bindings * 512 + v * 4 + rk] = red_buf0_1[thread_bindings * 512 + v * 4 + rk] + red_buf0_1[thread_bindings * 512 + v * 4 + rk + 1]
        T.tvm_storage_sync("shared.dyn")
        if rk == 0:
            C_local_1[n] = red_buf0_1[thread_bindings * 512 + v * 4]
    if rk == 0:
        for local_id_o in range(4):
            C_shared_1[thread_bindings // 32 * 256 + local_id_o % 2 * 128 + thread_bindings % 32 // 4 * 16 + local_id_o // 2 * 8 + thread_bindings % 4 * 2:thread_bindings // 32 * 256 + local_id_o % 2 * 128 + thread_bindings % 32 // 4 * 16 + local_id_o // 2 * 8 + thread_bindings % 4 * 2 + 2] = C_local_1[local_id_o * 2:local_id_o * 2 + 2]
    T.tvm_storage_sync("shared.dyn")
    if v < 32:
        C_1[v // 2 * 16384 + pid * 64 + rk * 16 + v % 2 * 8 + 9472:v // 2 * 16384 + pid * 64 + rk * 16 + v % 2 * 8 + 9472 + 8] = C_shared_1[rk * 256 + v * 8:rk * 256 + v * 8 + 8]
```

æˆ‘ä»¬æ‰“å°å‡ºç»Ÿè®¡å‡ºæ¥çš„ Alloc Entryï¼Œå…¶ä¹Ÿæ˜¯ç¬¦åˆé¢„æœŸçš„ã€‚
```cpp
Buffer Level
C_shared 1
B_dequantize_local 1
red_buf0 1
B_local 1
A_local 1
B_shared_full_tiles 1
A_shared_full_tiles 1
C_local 1
```

AllocEntryå°†å¸®åŠ©æˆ‘ä»¬æ„å»ºStmtEntryï¼Œåœ¨è®²è§£å¦‚ä½•æ„å»ºStmtEntryä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥è§‚å¯Ÿä¸€ä¸‹è¿™ä¸ªæ•°æ®ç»“æ„çš„æˆå‘˜:
- stmt, è®°å½•è¯¥æ¡ç›®çš„è¯­å¥çš„æŒ‡é’ˆ(ä¾‹å¦‚ForNode, IFç­‰ï¼ŒTVMçš„è¯­å¥å’Œè¡¨è¾¾å¼éƒ½æ´¾ç”Ÿè‡ªObject).
- scope_pair_offset: è®°å½•è¿™ä¸ªè¯­å¥åœ¨æ‰€æœ‰æ¡ç›®ä¸­çš„åç½®ï¼Œå¦‚æœæ˜¯å¤§äº0çš„ï¼Œè¡¨ç¤ºç°åœ¨è¿™ä¸ªæ˜¯è¯¥è¯­å¥çš„å¼€å¤´ï¼ˆæ¯”å¦‚Forå¾ªç¯çš„å¼€å¤´ï¼‰ï¼Œå¦‚æœæ˜¯å°äº0çš„ï¼Œåˆ™è¡¨ç¤ºç»“å°¾ï¼ˆæ¯”å¦‚Forå¾ªç¯çš„ç»“å°¾ï¼‰ã€‚
- touchedï¼šè®°å½•è¿™ä¸ªè¯­å¥åœ¨ä»£ç ä¸Šä¸‹æ–‡ä¸­è®¿é—®ï¼ˆè¯»æˆ–å†™ï¼‰åˆ°çš„å…±äº«å†…å­˜ç¼“å†²åŒºå˜é‡ã€‚

{% colorquote success %}
TVM Tips: å¦‚ä½•å¯è§†åŒ–stmt(åŠä¸€ä¸ªconst Object æŒ‡é’ˆ)ï¼Ÿ
åœ¨ TVM çš„ TIR ä¸­ï¼Œæ‰€æœ‰çš„è¯­å¥ï¼ˆStmtï¼‰å’Œè¡¨è¾¾å¼ï¼ˆPrimExprï¼‰éƒ½æ˜¯ç”±å¯¹è±¡ï¼ˆObjectï¼‰æ´¾ç”Ÿè€Œæ¥çš„ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨Objectçš„GetTypeKey()æ–¹æ³•è·å¾—è¿™ä¸ªObjectåˆ°åº•æ˜¯ä¸ªä»€ä¹ˆå†…å®¹ï¼Œå¦‚æœç¡®å®šæ˜¯è¯­å¥ï¼Œå¯ä»¥ä½¿ç”¨GetRef<Stmt>çš„æ–¹æ³•è·å¾—è¿™ä¸ªè¯­å¥ï¼Œå¹¶ä¸”é€šè¿‡TVMçš„IR Printeræ‰“å°å‡ºè¿™ä¸ªè¯­å¥ã€‚
```cpp
if (entry.stmt) {
  LOG(INFO) << "stmt type: " << entry.stmt->GetTypeKey();
  LOG(INFO) << "stmt: " << GetRef<Stmt>(static_cast<const StmtNode*>(entry.stmt));
}
```
{% endcolorquote %}

scope_pair_offsetï¼ˆä¸‹æ–‡ç®€ç§°offsetï¼‰ï¼Œ æ˜¯`SharedMemLinearAccessPatternFinder` ç±»ä¸­çš„ä¸€ä¸ªå…³é”®æ¦‚å¿µï¼Œå®ƒè¡¨ç¤ºè¯­å¥æ¡ç›®ï¼ˆStmtEntryï¼‰åœ¨çº¿æ€§è®¿é—®æ¨¡å¼ä¸­çš„ä½œç”¨åŸŸé…å¯¹åç§»é‡ã€‚è¿™ä¸ªåç§»é‡ç”¨äºè¡¨ç¤ºæŸä¸ªè¯­å¥æ¡ç›®ç›¸å¯¹äºå…¶ä½œç”¨åŸŸï¼ˆscopeï¼‰å¼€å§‹æˆ–ç»“æŸçš„è·ç¦»ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£å’Œåˆ†æè¯­å¥çš„åµŒå¥—ç»“æ„ã€‚
åŒæ ·çš„ï¼Œä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å‡ºå‘:

```c
for (int i = 0; i < N; ++i) {
    A[i] = B[i] + 1;
    if (A[i] > 0) {
        C[i] = A[i];
    } else {
        D[i] = -A[i];
    }
}
```
å‡è®¾æˆ‘ä»¬ä½¿ç”¨ `SharedMemLinearAccessPatternFinder` æ¥åˆ†æè¿™ä¸ªä»£ç ç‰‡æ®µçš„å…±äº«å†…å­˜è®¿é—®æ¨¡å¼ã€‚æˆ‘ä»¬ä¼šå¾—åˆ°å¦‚ä¸‹çš„çº¿æ€§åŒ–åºåˆ—ï¼ˆ`linear_seq_`ï¼‰ï¼š
```c

1. `StmtEntry` for `for` loop start:
    - `stmt`: `for` è¯­å¥å¼€å§‹
    - `scope_pair_offset`: +5 ï¼ˆè¡¨ç¤ºè¿™ä¸ªè¯­å¥çš„ä½œç”¨åŸŸç»“æŸæ¡ç›®è·ç¦»æ­¤æ¡ç›® 5 æ­¥ï¼‰
2. `StmtEntry` for `A[i] = B[i] + 1`:
    - `stmt`: `A[i] = B[i] + 1`
    - `scope_pair_offset`: 0 ï¼ˆæ™®é€šè¯­å¥ï¼Œæ²¡æœ‰è¿›å…¥æ–°çš„ä½œç”¨åŸŸï¼‰
3. `StmtEntry` for `if` statement start:
    - `stmt`: `if (A[i] > 0)`
    - `scope_pair_offset`: +2 ï¼ˆè¡¨ç¤º `if` è¯­å¥çš„ä½œç”¨åŸŸç»“æŸæ¡ç›®è·ç¦»æ­¤æ¡ç›® 2 æ­¥ï¼‰
4. `StmtEntry` for `C[i] = A[i]`:
    - `stmt`: `C[i] = A[i]`
    - `scope_pair_offset`: 0
5. `StmtEntry` for `else` statement start:
    - `stmt`: `else`
    - `scope_pair_offset`: 0
6. `StmtEntry` for `D[i] = -A[i]`:
    - `stmt`: `D[i] = -A[i]`
    - `scope_pair_offset`: 0
7. `StmtEntry` for `if` statement end:
    - `stmt`: `if` ç»“æŸ
    - `scope_pair_offset`: -3 ï¼ˆå›æº¯åˆ° `if` å¼€å§‹æ¡ç›®ï¼‰
8. `StmtEntry` for `for` loop end:
    - `stmt`: `for` è¯­å¥ç»“æŸ
    - `scope_pair_offset`: -7 ï¼ˆå›æº¯åˆ° `for` å¼€å§‹æ¡ç›®ï¼‰
```
é€šè¿‡ `scope_pair_offset` å€¼ï¼Œç¼–è¯‘å™¨èƒ½å¤Ÿç†è§£æ¯ä¸ªè¯­å¥çš„ä½œç”¨åŸŸè¾¹ç•Œå’ŒåµŒå¥—ç»“æ„ï¼š

- **æ‰¾åˆ°ä½œç”¨åŸŸçš„å¼€å§‹å’Œç»“æŸ**ï¼šé€šè¿‡æ­£å€¼ `offset`ï¼Œæˆ‘ä»¬çŸ¥é“ä»æŸä¸ªæ¡ç›®å¼€å§‹è¿›å…¥ä¸€ä¸ªä½œç”¨åŸŸï¼›é€šè¿‡è´Ÿå€¼ `offset`ï¼Œæˆ‘ä»¬çŸ¥é“åˆ°è¾¾äº†ä¸€ä¸ªä½œç”¨åŸŸçš„ç»“æŸã€‚
- **åˆ†æä½œç”¨åŸŸçš„åµŒå¥—ç»“æ„**ï¼šæ ¹æ®åç§»å€¼ï¼Œå¯ä»¥ç†è§£è¯­å¥ä¹‹é—´çš„åµŒå¥—å…³ç³»ï¼Œæ˜ç¡®æ¯ä¸ªè¯­å¥å±äºå“ªä¸ªä½œç”¨åŸŸï¼Œè¿™å¯¹äºå­˜æ´»æ€§åˆ†æå’Œå†…å­˜é‡ç”¨çš„è§„åˆ’éå¸¸é‡è¦ã€‚

åŒæ ·ï¼Œä»¥åˆšåˆšçš„çŸ©é˜µä¹˜æ³•ä¸ºä¾‹å­ï¼Œæˆ‘ä»¬æ‰“å°å‡ºStmtEntryçš„å†…å®¹ã€‚

```
stmt type: tir.AttrStmt offset 23
no touched buffer
stmt type: tir.For offset 7
no touched buffer
stmt type: tir.For offset 1
no touched buffer
stmt type: tir.For offset -1
no touched buffer
stmt type: tir.For offset 1
no touched buffer
stmt type: tir.For offset -1
no touched buffer
stmt type: tir.For offset 1
no touched buffer
stmt type: tir.For offset -1
no touched buffer
stmt type: tir.For offset -7
touched buffer:
  buffer A_shared_full_tiles
  buffer B_shared_full_tiles
  buffer B_shared_full_tiles
stmt type: tir.For offset 7
no touched buffer
stmt type: tir.IfThenElse offset 1
no touched buffer
stmt type: tir.IfThenElse offset -1
no touched buffer
stmt type: tir.IfThenElse offset 1
no touched buffer
stmt type: tir.IfThenElse offset -1
no touched buffer
stmt type: tir.IfThenElse offset 1
no touched buffer
stmt type: tir.IfThenElse offset -1
no touched buffer
stmt type: tir.For offset -7
touched buffer:
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
  buffer red_buf0
stmt type: tir.IfThenElse offset 3
no touched buffer
stmt type: tir.For offset 1
no touched buffer
stmt type: tir.For offset -1
no touched buffer
stmt type: tir.IfThenElse offset -3
touched buffer:
  buffer C_shared
stmt type: tir.IfThenElse offset 1
no touched buffer
stmt type: tir.IfThenElse offset -1
touched buffer:
  buffer C_shared
stmt type: tir.AttrStmt offset -23
no touched buffer
```

æ‹¿åˆ°äº†StmtEntryï¼Œå°±å¯ä»¥Bufferçš„ç”Ÿå‘½å‘¨æœŸåˆ†æäº†ï¼Œæ­¤å¤„çš„ä»£ç ä¹Ÿéå¸¸ä¹‹ç®€ä»‹å’Œæ˜äº†, é€šè¿‡ç»Ÿè®¡bufferæœ€å…ˆè¢«touchçš„åœ°æ–¹å’Œæœ€åè¢«touchçš„åœ°æ–¹ï¼Œä»è€Œå¾—åˆ°bufferçš„genå’Œkill Node.
```

  /*!
   * \brief Liveness analysis to find gen and kill point of each variable.
   * \param seq the linear pattern of storage access
   */
  void LivenessAnalysis(const std::vector<StmtEntry>& seq) {
    // find kill point, do a reverse linear scan.
    std::unordered_set<const VarNode*> touched;
    for (size_t i = seq.size(); i != 0; --i) {
      const StmtEntry& s = seq[i - 1];
      for (const VarNode* buffer : s.touched) {
        if (!touched.count(buffer)) {
          touched.insert(buffer);
          event_map_[s.stmt].kill.push_back(buffer);
        }
      }
    }
    // find gen point, do forward scan
    touched.clear();
    for (size_t i = 0; i < seq.size(); ++i) {
      int64_t offset = seq[i].scope_pair_offset;
      if (offset < 0) continue;
      const StmtEntry& s = seq[i + offset];
      for (const VarNode* buffer : s.touched) {
        if (!touched.count(buffer)) {
          touched.insert(buffer);
          event_map_[s.stmt].gen.push_back(buffer);
        }
      }
    }
  }
```

æœ€åï¼Œé€šè¿‡PlanMemoryæ¥æ”¹å˜Bufferçš„è®¿å­˜ï¼Œç„¶è€Œåœ¨è¿™ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦æ ¹æ®ç”Ÿå‘½å‘¨æœŸåˆ†æçš„ç»“æœç”Ÿæˆä¸€ä¸ªåˆå¹¶æ–¹æ¡ˆï¼Œè¿™é‡Œåˆæœ‰ä¸‰ä¸ªè¾…åŠ©æ•°æ®ç»“æ„ï¼šå­˜å‚¨ç©ºé—²çš„å†…å­˜å—åˆ—è¡¨ï¼ˆconst_free_map_ å’Œ sym_free_list_ï¼‰ï¼Œä»¥åŠåˆ†é…ä¿¡æ¯æ˜ å°„(alloc_map_)ï¼Œéå†æ¯ä¸ªè¯­å¥æ¡ç›®ï¼Œåˆ†æå…¶ä¸­çš„å†…å­˜è®¿é—®å’Œé‡Šæ”¾æ“ä½œï¼Œå½“ç¢°åˆ° kill äº‹ä»¶çš„æ—¶å€™é‡Šæ”¾ä¸å†éœ€è¦çš„å†…å­˜å—ï¼Œå½“ç¢°åˆ°gen äº‹ä»¶çš„æ—¶å€™åˆ†é…æ–°çš„å†…å­˜å—æˆ–é‡ç”¨å·²é‡Šæ”¾çš„å†…å­˜å—ã€‚

`kill` å¤„ç†çš„ä»£ç è§£è¯»ï¼š

```cpp
if (it != event_map_.end() && seq[i].scope_pair_offset <= 0) {
    for (const VarNode* var : it->second.kill) {
        if (!is_leaf_alloc(var)) this->Free(var);
    }
}

```

- éå†æ¯ä¸ª `StmtEntry` æ¡ç›®ï¼Œæ£€æŸ¥ `event_map_`ï¼ˆäº‹ä»¶æ˜ å°„è¡¨ï¼‰ä¸­æ˜¯å¦å­˜åœ¨ä¸è¯¥æ¡ç›®ç›¸å…³çš„ `kill` äº‹ä»¶ã€‚
- `kill` äº‹ä»¶è¡¨ç¤ºæŸäº›å†…å­˜å˜é‡åœ¨å½“å‰ä½œç”¨åŸŸç»“æŸæ—¶å·²ç»ä¸å†éœ€è¦ã€‚å¯¹äºè¿™äº›å˜é‡ï¼Œè°ƒç”¨ `Free` æ–¹æ³•å°†å…¶ä»å½“å‰ä½¿ç”¨çš„å†…å­˜ä¸­ç§»é™¤ï¼Œå¹¶å°†å…¶æ ‡è®°ä¸ºå¯é‡ç”¨çŠ¶æ€ï¼ˆæ”¾å…¥ç©ºé—²åˆ—è¡¨ `const_free_map_` æˆ– `sym_free_list_` ä¸­ï¼‰ã€‚

`gen` å¤„ç†çš„ä»£ç è§£è¯»ï¼š

```cpp
if (it != event_map_.end() && seq[i].scope_pair_offset >= 0) {
    for (const VarNode* var : it->second.gen) {
        ICHECK(shmem_allocs_.count(var));
        const AllocateNode* alloc = shmem_allocs_[var];
        StorageEntry* dst_entry = FindAlloc(alloc);
        alloc_map_[var] = dst_entry;
    }
}

```

- éå†æ¯ä¸ª `StmtEntry` æ¡ç›®ï¼Œæ£€æŸ¥ `event_map_` ä¸­æ˜¯å¦å­˜åœ¨ä¸è¯¥æ¡ç›®ç›¸å…³çš„ `gen` äº‹ä»¶ã€‚
- `gen` äº‹ä»¶è¡¨ç¤ºæŸäº›å†…å­˜å˜é‡åœ¨å½“å‰ä½œç”¨åŸŸå¼€å§‹æ—¶éœ€è¦è¢«åˆ†é…ã€‚
- å¯¹äºè¿™äº›å˜é‡ï¼š
    - ä½¿ç”¨ `FindAlloc` æ–¹æ³•æŸ¥æ‰¾ä¸€ä¸ªåˆé€‚çš„å†…å­˜å—è¿›è¡Œåˆ†é…ã€‚å¦‚æœå½“å‰æ²¡æœ‰å¯é‡ç”¨çš„å†…å­˜å—ï¼Œåˆ™ä¼šåˆ†é…æ–°çš„å†…å­˜å—ã€‚
    - æ›´æ–° `alloc_map_`ï¼Œå°†åˆ†é…ä¿¡æ¯æ˜ å°„åˆ°ç›¸åº”çš„å˜é‡ã€‚

`PlanMemory` æ–¹æ³•çš„æ ¸å¿ƒæ˜¯æ ¹æ®å…±äº«å†…å­˜å—çš„ç”Ÿå­˜å‘¨æœŸå’Œä½œç”¨åŸŸå±‚æ¬¡ï¼Œå†³å®šå“ªäº›å†…å­˜å—å¯ä»¥è¢«åˆå¹¶æˆ–é‡ç”¨ã€‚

```cpp
if (it != event_map_.end() && seq[i].scope_pair_offset >= 0) {
    for (const VarNode* var : it->second.gen) {
        ICHECK(shmem_allocs_.count(var));
        const AllocateNode* alloc = shmem_allocs_[var];
        StorageEntry* dst_entry = FindAlloc(alloc);
        alloc_map_[var] = dst_entry;
    }
}

```

- `FindAlloc` æ–¹æ³•ç”¨äºæŸ¥æ‰¾ä¸€ä¸ªåˆé€‚çš„å­˜å‚¨æ¡ç›®ï¼ˆ`StorageEntry`ï¼‰æ¥åˆ†é…ç»™å½“å‰å˜é‡ã€‚
- åœ¨å†…å­˜é‡ç”¨è¿‡ç¨‹ä¸­ï¼Œå¦‚æœæ‰¾åˆ°åˆé€‚çš„ç©ºé—²å†…å­˜å—ï¼Œåˆ™å°†è¯¥å—åˆ†é…ç»™å½“å‰å˜é‡å¹¶æ›´æ–°å…¶åˆ†é…çŠ¶æ€ï¼›å¦åˆ™ï¼Œåˆ†é…ä¸€ä¸ªæ–°çš„å†…å­˜å—ã€‚
- `alloc_map_` ç”¨äºè®°å½•æ¯ä¸ªå˜é‡çš„å­˜å‚¨æ¡ç›®ä¿¡æ¯ï¼Œç¡®ä¿å†…å­˜åˆ†é…çš„æ­£ç¡®æ€§ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ†æStorageEntryæ¥ç¡®å®šæœ€ç»ˆçš„shared memoryçš„æ€»å­˜å‚¨å¤§å°ã€‚

```cpp
  // Calculate offset for each buffer based on the alignment of each layer
for (const StorageEntry* e : all_entry) {
    PrimExpr max_inner_offset = 0;
    for (int i = 0; i < static_cast<int>(e->allocs.size()); i++) {
        PrimExpr inner_offset = 0;
        for (const VarNode* buffer : e->allocs[i]) {
            const AllocateNode* alloc = shmem_allocs_[buffer];
            buffer_byte_offsets_[buffer] = merged_alloc_size_ + inner_offset;
            inner_offset += alloc->extents[0] * alloc->dtype.bytes() * alloc->dtype.lanes();
            inner_offset += indexmod(align[i] - indexmod(inner_offset, align[i]), align[i]);
        }
        max_inner_offset = max(max_inner_offset, inner_offset);
    }
    merged_alloc_size_ += max_inner_offset;
}
```

ä¹‹åï¼Œå†è¯­æ³•æ ‘çš„å¼€å§‹æ’å…¥ä¸€ä¸ªæ–°çš„AllocateèŠ‚ç‚¹ï¼Œå¹¶ä¸”è·³è¿‡æ‰€æœ‰åŸæœ¬çš„AllocateèŠ‚ç‚¹ï¼Œå·²ç»æ›´æ–°DeclBufferèŠ‚ç‚¹ã€‚

```cpp
allocated_ = true;
Allocate new_body(merged_buf_var_, DataType::UInt(8), {merged_alloc_size_}, const_true(),
                  StmtExprMutator::VisitStmt(op->body));
return AttrStmt(op->node, op->attr_key, op->value, new_body, op->span);

Stmt VisitStmt_(const AllocateNode* op) final {
  if (IsAppropriateSharedMemory(op->buffer_var)) {
    return StmtExprMutator::VisitStmt(op->body);
  }
  return StmtExprMutator::VisitStmt_(op);
}

Stmt VisitStmt_(const DeclBufferNode* op) final {
  auto node = Downcast<DeclBuffer>(StmtExprMutator::VisitStmt_(op));
  if (auto new_buf = GetUpdatedBuffer(node->buffer); !new_buf.same_as(node->buffer)) {
    node.CopyOnWrite()->buffer = new_buf;
  }
  return std::move(node);
}
```

é€šè¿‡è®¿é—®BufferLoadå’ŒBufferStoreèŠ‚ç‚¹ï¼Œæ›´æ–°æˆunifiy bufferçš„è®¿å­˜ä½ç½®ç­‰ï¼Œä¾‹å¦‚ä»`B_shared[i, j]` å˜æˆ `smem[i * B_stride[0] + j + offset]`

```cpp
PrimExpr VisitExpr_(const BufferLoadNode* op) final {
  auto node = Downcast<BufferLoad>(StmtExprMutator::VisitExpr_(op));
  return VisitBufferAccess(std::move(node));
}

Stmt VisitStmt_(const BufferStoreNode* op) final {
  auto node = Downcast<BufferStore>(StmtExprMutator::VisitStmt_(op));
  return VisitBufferAccess(std::move(node));
}
```


### BUGçš„å‘ç°å’Œæ”¹è¿›

ä¸Šè¿°Passåœ¨GEMMé‡Œå¯ä»¥è·å¾—ä¸é”™çš„æ•ˆæœï¼Œä½†æ˜¯ä¸€æ–¹é¢ï¼Œå¤ç”¨æ•ˆæœè¾¾ä¸åˆ°æœ€å¥½ï¼Œå¦ä¸€æ–¹é¢ï¼Œå¤„ç†touched bufferçš„é€»è¾‘æœ‰ä¸€ç‚¹é—®é¢˜ã€‚

ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œå¤ç”¨æ•ˆæœè¾¾ä¸åˆ°æœ€å¥½ï¼Œè¿™ä¸ªæ˜¯å› ä¸º`StorageRewrite`è¿™ä¸ªPassï¼Œä¼šè¿›è¡Œä¸€ä¸ªç®€å•çš„Bufferå¤ç”¨ï¼Œè¿™ä¸ªæ–¹æ³•ä¿è¯äº†ä¸€å®šçš„å¯è¯»æ€§ï¼Œä½†æ˜¯å¾ˆå‘†ï¼Œå…·ä½“çš„è®¨è®ºè§æˆ‘ä¹‹å‰çš„PRï¼Œhttps://github.com/apache/tvm/pull/16342 .

```cpp
int8 A_shared[32];
int8 B_shared[32];
int8 C_shared[64]; 
// will be reused as A_shared[32], B_shared[64],  results in 32 half elements space waste.
```

å¦‚æ­¤ï¼Œä¼šæµªè´¹ä¸€éƒ¨åˆ†çš„å­˜å‚¨ï¼Œæˆ‘å¼•å…¥äº†ä¸€ä¸ªoptionï¼Œ`tir.merge_static_smem`æ¥å…³é—­`StorageRewrite`çš„merge.

```python
with tvm.transform.PassContext(config={
    "cuda.kernels_output_dir": "debug",
    "tir.merge_static_smem": True
}):
    rt_mod = tvm.build(ir_mod)
```

ä½†æ˜¯ä¸ºäº†ä¿è¯StaticSharedMemoryçš„å¯è¯»æ€§ï¼Œè¿™ä¸ªoptioné»˜è®¤æ˜¯å…³é—­çš„ã€‚

ç¬¬äºŒä¸ªé—®é¢˜ï¼Œç»“åˆæˆ‘ä»¬ä¹‹å‰çš„åˆ†æï¼Œæˆ‘ä»¬çŸ¥é“Shared Memoryçš„AllocèŠ‚ç‚¹éƒ½æ˜¯åœ¨Level 1çš„ï¼Œè€Œé€šè¿‡touched_bufferæ›´æ–°çš„ä»£ç ï¼š
```
if (it != alloc_info_.end() && it->second.alloc) {
  ICHECK_LT(it->second.level, scope_.size());
  if (IsAppropriateSharedMemory(GetRef<Var>(buf))) {
    scope_[it->second.level].touched.push_back(buf);
  }
}
```

ä¸éš¾å‘ç°ï¼Œå…¶æ¯æ¬¡éƒ½ä¼šæŠŠtouched bufferæ”¾åˆ°æœ€å¤–å›´çš„(é™¤äº†AttrStmt)Entryä¸Šï¼Œè¿™ä¸ªå¯¹äºçŸ©é˜µä¹˜æ³•æ¥è¯´åˆšå¥½æ˜¯å¯¹çš„ï¼Œä½†æ˜¯ç»†æƒ³æ¥çœ‹ï¼Œè¿™ä¸ªtouched bufferå…¶å®åº”è¯¥æ”¾åˆ°æœ€å†…å±‚çš„Entryä¸Šï¼ŒLivenessåˆ†æä¸­çš„Genå’ŒKill Pointæ‰ä¸ä¼šå‡ºé”™ï¼Œä¸ºäº†éªŒè¯è¿™ä¸ªçŒœæƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªç®€å•çš„batched gemmä¸ºä¾‹å­ï¼ˆbatchç»´åº¦ä¸å¹¶è¡ŒåŒ–ï¼‰ï¼Œè¿™æ ·æœ€å¤–å›´çš„(é™¤äº†AttrStmt)Entryå°±æ˜¯ä¸€ä¸ªå®Œæ•´çš„ForLoopï¼Œè¿™æ ·æ‰€æœ‰çš„touched bufferéƒ½ä¼šè¢«æ”¾åˆ°è¿™ä¸ªEntryä¸Šï¼Œé‚£ä¹ˆè¯¥Passå°±å®Œå…¨ä¸ä¼šå¤ç”¨ä»»ä½•Buffer(å› ä¸ºæ¯ä¸ªä»£Bufferçš„Gen Pointéƒ½åœ¨AttrStmtçš„å¼€å¤´ï¼Œåˆ°AttrStmtçš„ç»“å°¾), åœ¨Stream-Kçš„å®ç°ä¸­ï¼Œè¿™ä¸ªåœºæ™¯æ˜¯æ›´åŠ å¤æ‚çš„ï¼Œå…¶è¡¨è¾¾å¼ä¸º:

```python
while xxx:
	...
for ko in :
	...
for n in :
	...
for n in :
	...
```

æ‰€ä»¥è¯¥é—®é¢˜çš„è§£æ³•æœ¬è´¨ä¸Šä¹Ÿå¾ˆç®€å•ï¼Œå°±æ˜¯æŠŠtouched bufferçš„æ›´æ–°æ¨¡å¼æ¢ä¸€ä¸‹ï¼Œå°½å¯èƒ½ä½¿ç”¨æœ€å†…å±‚çš„Entryè€Œä¸æ˜¯æœ€å¤–å±‚çš„ã€‚

```cpp
scope_[scope_.size() - 1].touched.push_back(buf);
```

### æ€»ç»“

å¥½ä¹…æ²¡æœ‰å†™blogäº†ï¼Œä¸€åƒä¸ªåŸºäºTVMçš„é¡¹ç›®ï¼Œå°±æœ‰ä¸€åƒä¸ªè¢«çˆ†æ”¹è¿‡çš„TVMã€‚ç›¸ä¿¡å¾ˆå¤šTVMçš„ä½¿ç”¨è€…å’Œåˆå­¦è€…å¯¹æ”¹åŠ¨CPPçš„Passæœ›è€Œå´æ­¥ï¼Œç¬”è€…è§‰å¾—æœ€ä¸»è¦çš„å‘è¿˜æ˜¯æ–‡æ¡£å¤ªå°‘äº†(ä½†æ˜¯ç¤¾åŒºä¹Ÿæ­£åœ¨æ–½å·¥)ï¼ŒTVMçš„CPPä»£ç éå¸¸ä¹‹ä¼˜ç¾ï¼Œå¸¸çœ‹å¸¸æ–°ğŸ˜­ï¼Œæ„Ÿè°¢chengyuä¸€èµ·åˆ†æå’Œå®šä½äº†ä¸€ä¸‹Bugï¼Œæˆ‘æ­£åœ¨ç³ŠStream-Kçš„å®ç°æ­£åœ¨æ–½å·¥ä¸­:) [LeiWang1999/Stream-k.tvm (github.com)](https://github.com/LeiWang1999/Stream-k.tvm)ï¼Œä»¥åŠæ¬¢è¿å¤§å®¶å…³æ³¨æˆ‘æœ€è¿‘åœ¨å†™çš„é¡¹ç›®[microsoft/BitBLAS](https://github.com/microsoft/BitBLAS) !

